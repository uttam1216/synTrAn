{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda64afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e454d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import socket\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence  #, masked_cross_entropy\n",
    "from masked_cross_entropy import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "# %matplotlib inline\n",
    "# import visdom\n",
    "# vis = visdom.Visdom()\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20963d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b2240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb\n",
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bf3968",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3  # Count default tokens\n",
    "\n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            word = str(word)\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "#             print(word)\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed: return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words %s / %s = %.4f' % (\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3  # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.index_word(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea7eac4",
   "metadata": {},
   "source": [
    "To read the data file we will split the file into lines, and then split lines into pairs. The files are all English → Other Language, so if we want to translate from Other Language → English I added the reverse flag to reverse the pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14b1ee73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_langs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    filename = './%s-%s' % (lang1, lang2)\n",
    "    print(filename)\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "#     print(lines)\n",
    "    # pairs = []\n",
    "    # input_lang = []\n",
    "    # output_lang = []\n",
    "\n",
    "    pairs = [[s for s in l.split(':')] for l in lines]\n",
    "#     print(pairs)\n",
    "\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "#     print(input_lang)\n",
    "#     print(output_lang)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2904acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_LENGTH = 10\n",
    "MAX_LENGTH = 5760\n",
    "\n",
    "def filter_pairs(pairs):\n",
    "    filtered_pairs = []\n",
    "    for pair in pairs:\n",
    "        filtered_pairs.append(pair)\n",
    "    return filtered_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceea1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(lang1_name, lang2_name, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_langs(lang1_name, lang2_name, reverse)\n",
    "    print(\"Read %d sentence pairs\" % len(pairs))\n",
    "\n",
    "    pairs = filter_pairs(pairs)\n",
    "#     print(pairs)\n",
    "    print(\"Filtered to %d pairs\" % len(pairs))\n",
    "\n",
    "    print(\"Indexing words...\")\n",
    "    \n",
    "    for pair in pairs:\n",
    "#         print(len(pair))\n",
    "#         print(pair)\n",
    "        input_lang.index_words(pair[0])\n",
    "        output_lang.index_words(pair[1])\n",
    "\n",
    "#     print('Indexed %d words in input language, %d words in output' % (input_lang.n_words, output_lang.n_words))\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcba78f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "./way-base\n",
      "Read 1303 sentence pairs\n",
      "Filtered to 1303 pairs\n",
      "Indexing words...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'200072875'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepare_data('way', 'base', False)\n",
    "output_lang.index2word[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92c893da",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4751d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in pairs:\n",
    "    input_sentence = pair[0]\n",
    "    output_sentence = pair[1]\n",
    "    keep_input = True\n",
    "    keep_output = True\n",
    "    for word in input_sentence.split(' '):\n",
    "        if word not in input_lang.word2index:\n",
    "            keep_input=False\n",
    "            break\n",
    "    for word in output_sentence.split(' '):\n",
    "        if word not in output_lang.word2index:\n",
    "            keep_output=False\n",
    "            break\n",
    "    if keep_input and keep_output:\n",
    "        keep_pairs.append(pair)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d764d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes_from_sentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')] + [EOS_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11dd5093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq, max_length):\n",
    "    seq += [PAD_token for i in range(max_length - len(seq))]\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60850e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(batch_size):\n",
    "    input_seqs = []\n",
    "    target_seqs = []\n",
    "    for i in range(batch_size):\n",
    "        pair = random.choice(pairs)\n",
    "#         print(pair)\n",
    "        input_seqs.append(indexes_from_sentence(input_lang, pair[0]))\n",
    "        target_seqs.append(indexes_from_sentence(output_lang, pair[1]))\n",
    "\n",
    "    seq_pairs = sorted(zip(input_seqs, target_seqs), key=lambda p: len(p[0]), reverse=True)\n",
    "    input_seqs, target_seqs = zip(*seq_pairs)\n",
    "\n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "    target_lengths = [len(s) for s in target_seqs]\n",
    "    target_padded = [pad_seq(s, max(target_lengths)) for s in target_seqs]\n",
    "\n",
    "    input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "    target_var = Variable(torch.LongTensor(target_padded)).transpose(0, 1)\n",
    "\n",
    "    if USE_CUDA:\n",
    "        input_var = input_var.cuda()\n",
    "        target_var = target_var.cuda()\n",
    "\n",
    "    return input_var, input_lengths, target_var, target_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9ae3ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seqs, input_lengths, hidden=None):\n",
    "        embedded = self.embedding(input_seqs)\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs)  # unpack (back to padded)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:]  # Sum bidirectional outputs\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d073e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        attn_energies = Variable(torch.zeros(this_batch_size, max_len))  # B x S\n",
    "\n",
    "        if USE_CUDA:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        for b in range(this_batch_size):\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[:, b], encoder_outputs[i, b].unsqueeze(0))\n",
    "\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "\n",
    "    def score(self, hidden, encoder_output):\n",
    "        if self.method == 'dot':\n",
    "            energy = torch.dot(hidden.view(-1), encoder_output.view(-1))\n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = torch.dot(hidden.view(-1), energy.view(-1))\n",
    "        elif self.method == 'concat':\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 1))\n",
    "            energy = torch.dot(self.v.view(-1), energy.view(-1))\n",
    "        return energy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2246ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = Attn('concat', hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "        word_embedded = self.embedding(word_input).view(1, 1, -1)  # S=1 x B x N\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        context = context.transpose(0, 1)\n",
    "\n",
    "        rnn_input = torch.cat((word_embedded, context), 2)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        output = output.squeeze(0)  # B x N\n",
    "        output = F.log_softmax(self.out(torch.cat((output, context), 1)))\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca40139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "        batch_size = input_seq.size(0)\n",
    "        embedded = self.embedding(input_seq)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        embedded = embedded.view(1, batch_size, self.hidden_size)\n",
    "\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = F.tanh(self.concat(concat_input))\n",
    "\n",
    "        output = self.out(concat_output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5b49215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (gru): GRU(10, 10, num_layers=2, dropout=0.1, bidirectional=True)\n",
      ")\n",
      "LuongAttnDecoderRNN(\n",
      "  (embedding): Embedding(10, 10)\n",
      "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (gru): GRU(10, 10, num_layers=2, dropout=0.1)\n",
      "  (concat): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (out): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (attn): Attn(\n",
      "    (attn): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder_test = EncoderRNN(10, 10, 2)\n",
    "decoder_test = LuongAttnDecoderRNN('general', 10, 10, 2)\n",
    "print(encoder_test)\n",
    "print(decoder_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "345ac8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure models\n",
    "attn_model = 'dot'\n",
    "hidden_size = 100\n",
    "n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_epochs = 20000\n",
    "epoch = 0\n",
    "plot_every = 1\n",
    "print_every = 1\n",
    "evaluate_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4574853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderRNN(input_lang.n_words, hidden_size, n_layers, dropout=dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, hidden_size, output_lang.n_words, n_layers, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9f05b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "start = time.time()\n",
    "plot_losses = []\n",
    "print_loss_total = 0\n",
    "plot_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dee8314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (as_minutes(s), as_minutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55e3d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_batches, input_lengths, target_batches, target_lengths, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]  # Use last (forward) hidden state from encoder\n",
    "\n",
    "    max_target_length = max(target_lengths)\n",
    "    all_decoder_outputs = Variable(torch.zeros(max_target_length, batch_size, decoder.output_size))\n",
    "\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        all_decoder_outputs = all_decoder_outputs.cuda()\n",
    "\n",
    "    print(\"The max target length this time is \\t\", max_target_length)\n",
    "    for t in range(max_target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "\n",
    "        all_decoder_outputs[t] = decoder_output\n",
    "        decoder_input = target_batches[t]\n",
    "\n",
    "    loss = masked_cross_entropy(\n",
    "        all_decoder_outputs.transpose(0, 1).contiguous(),\n",
    "        target_batches.transpose(0, 1).contiguous(),\n",
    "        target_lengths\n",
    "    )\n",
    "    loss.backward()\n",
    "\n",
    "    ec = torch.nn.utils.clip_grad_norm(encoder.parameters(), clip)\n",
    "    dc = torch.nn.utils.clip_grad_norm(decoder.parameters(), clip)\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data, ec, dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1171dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecs = []\n",
    "dcs = []\n",
    "eca = 0\n",
    "dca = 0\n",
    "epoch=0\n",
    "# while epoch < n_epochs:\n",
    "#     epoch += 1\n",
    "#     print('epoch \\t', epoch)\n",
    "#     input_batches, input_lengths, target_batches, target_lengths = random_batch(batch_size)\n",
    "\n",
    "#     loss, ec, dc = train(\n",
    "#         input_batches, input_lengths, target_batches, target_lengths,\n",
    "#         encoder, decoder,\n",
    "#         encoder_optimizer, decoder_optimizer, criterion\n",
    "#     )\n",
    "\n",
    "#     print_loss_total += loss\n",
    "#     plot_loss_total += loss\n",
    "#     eca += ec\n",
    "#     dca += dc\n",
    "#     if epoch==0:\n",
    "#         continue\n",
    "#     if epoch % print_every == 0:\n",
    "#         print_loss_avg = print_loss_total / print_every\n",
    "#         print_loss_total = 0\n",
    "#         print_summary = '%s (%d %d%%) %.4f' % (\n",
    "#         time_since(start, epoch / n_epochs), epoch, epoch / n_epochs * 100, print_loss_avg)\n",
    "#         print(print_summary)\n",
    "\n",
    "#     if epoch % evaluate_every == 0:\n",
    "#         print(\"Hello\")\n",
    "#         # evaluate_randomly()\n",
    "\n",
    "#     if epoch % plot_every == 0:\n",
    "#         plot_loss_avg = plot_loss_total / plot_every\n",
    "#         plot_losses.append(plot_loss_avg)\n",
    "#         plot_loss_total = 0\n",
    "#         ecs.append(eca / plot_every)\n",
    "#         dcs.append(dca / plot_every)\n",
    "#         ecs_win = 'encoder grad (%s)' % hostname\n",
    "#         dcs_win = 'decoder grad (%s)' % hostname\n",
    "#         eca = 0\n",
    "#         dca = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85cd1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_batches, input_lengths, target_batches, target_lengths = random_batch(batch_size)\n",
    "# print(input_batches.shape)\n",
    "# print(input_lengths)\n",
    "# # encoder(input_batches, input_lengths, None)\n",
    "# # input_lengths = [len(input_seq)]\n",
    "\n",
    "\n",
    "# # print(target_batches)\n",
    "# # print(target_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11757e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_seq=[\"42195876\"]\n",
    "# input_lengths = [len(input_seq)]\n",
    "# input_seqs = [indexes_from_sentence(input_lang, input_seq[0])]\n",
    "# input_batches = Variable(torch.LongTensor(input_seqs), volatile=True).transpose(0, 1)\n",
    "# # print(input_batches.shape)\n",
    "# # print(input_lengths)\n",
    "# if USE_CUDA:\n",
    "#         input_batches = input_batches.cuda()\n",
    "# # print(input_seqs)\n",
    "# encoder_outputs, encoder_hidden=encoder(input_batches, input_lengths, None)\n",
    "# decoder_input = Variable(torch.LongTensor([SOS_token]), volatile=True)\n",
    "# decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "# if USE_CUDA:\n",
    "#         decoder_input = decoder_input.cuda()\n",
    "# print(decoder_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50602efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(encoder.state_dict(), 'encoder20000_1500_with_new.dict')\n",
    "# torch.save(decoder.state_dict(), 'decoder20000_1500_with_new.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2418e63a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LuongAttnDecoderRNN:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([1549, 100]) from checkpoint, the shape in current model is torch.Size([1548, 100]).\n\tsize mismatch for out.weight: copying a param with shape torch.Size([1549, 100]) from checkpoint, the shape in current model is torch.Size([1548, 100]).\n\tsize mismatch for out.bias: copying a param with shape torch.Size([1549]) from checkpoint, the shape in current model is torch.Size([1548]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12256/1100918632.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'encoder20000_1500_with_new.dict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'decoder20000_1500_with_new.dict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1666\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1667\u001b[1;33m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[0;32m   1668\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0;32m   1669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LuongAttnDecoderRNN:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([1549, 100]) from checkpoint, the shape in current model is torch.Size([1548, 100]).\n\tsize mismatch for out.weight: copying a param with shape torch.Size([1549, 100]) from checkpoint, the shape in current model is torch.Size([1548, 100]).\n\tsize mismatch for out.bias: copying a param with shape torch.Size([1549]) from checkpoint, the shape in current model is torch.Size([1548])."
     ]
    }
   ],
   "source": [
    "encoder.load_state_dict(torch.load('encoder20000_1500_with_new.dict'))\n",
    "decoder.load_state_dict(torch.load('decoder20000_1500_with_new.dict'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b4e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_show_attention(input_sentence, target_sentence=None):\n",
    "    output_words, attentions = evaluate(input_sentence)\n",
    "    output_sentence = ' '.join(output_words)\n",
    "    print('>', input_sentence)\n",
    "    if target_sentence is not None:\n",
    "        print('=', target_sentence)\n",
    "    print('<', output_sentence)\n",
    "\n",
    "    show_attention(input_sentence, output_words, attentions)\n",
    "    win = 'evaluted (%s)' % hostname\n",
    "    text = '<p>&gt; %s</p><p>= %s</p><p>&lt; %s</p>' % (input_sentence, target_sentence, output_sentence)\n",
    "    vis.text(text, win=win, opts={'title': win})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b76705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_seq, max_length=MAX_LENGTH):\n",
    "#     input_lengths = [len(s) for s in input_seq]\n",
    "#     print(max_length)\n",
    "#     input_lengths = [len(input_seq)]\n",
    "#     input_seqs = [indexes_from_sentence(input_lang, input_seq)]\n",
    "#     input_batches = Variable(torch.LongTensor(input_seqs), volatile=True).transpose(0, 1)\n",
    "# #     print(input_batches)\n",
    "#     print(len(input_lengths))\n",
    "#     print(input_seqs)\n",
    "    input_batches, input_lengths=random_batchs(1,input_seq)\n",
    "#     print(input_seq)\n",
    "    if USE_CUDA:\n",
    "        input_batches = input_batches.cuda()\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token]), volatile=True)  # SOS\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]  # Use last (forward) hidden state from encoder\n",
    "\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "\n",
    "    for di in range(max_length):\n",
    "#         print(\"I am here\")\n",
    "#         print(di)\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "        decoder_attentions[di, :decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "#         print(topv)\n",
    "        ni = topi[0][0]\n",
    "        ni=ni.item()\n",
    "#         print(ni)\n",
    "#         print(decoded_words)\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([ni]))\n",
    "        if USE_CUDA:\n",
    "            decoder_input = decoder_input.cuda()\n",
    "\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f37bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batchs(batch_size,pair):\n",
    "    input_seqs = []\n",
    "    target_seqs = []\n",
    "#     print(len(pair))\n",
    "    input_seqs.append(indexes_from_sentence(input_lang, pair))\n",
    "#     print(input_seqs)\n",
    "    seq_pairs = sorted(zip(input_seqs), key=lambda p: len(p[0]), reverse=True)\n",
    "\n",
    "    input_lengths = [len(s) for s in input_seqs]\n",
    "    input_padded = [pad_seq(s, max(input_lengths)) for s in input_seqs]\n",
    "#     print(input_padded)\n",
    "#     target_lengths = [len(s) for s in target_seqs]\n",
    "#     target_padded = [pad_seq(s, max(target_lengths)) for s in target_seqs]\n",
    "\n",
    "    input_var = Variable(torch.LongTensor(input_padded)).transpose(0, 1)\n",
    "\n",
    "    if USE_CUDA:\n",
    "        input_var = input_var.cuda()\n",
    "\n",
    "    return input_var, input_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = random.choice(pairs)\n",
    "print(pair[0])\n",
    "# print(len(pair[0]))\n",
    "decoded_words,decoded_attention=evaluate(pair[0],len(pair[0])+2)\n",
    "print(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f538c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoded_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee082e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pair[0]))\n",
    "input_batch, input_lengths=random_batchs(1,pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a39a4",
   "metadata": {},
   "source": [
    "Evaluation Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3669e7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairahh='13848825 27149319 30405528 30405528 30405528 128131495 128463452 256418832 262579556 262580848 262580849 262582711 262614390 262616020 262616022 262617734 262799005 262799006 262799624 262803520 304680074 332053119 346992934 346993984 346993987 482261338 482261339 507522243 927900710 1008096491 1008096492 1008117702'\n",
    "#\n",
    "# print(len(pairahh))\n",
    "evaluate(pairahh,35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab54bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairahh='13800389 200072875 262802895 262802896 482261339 482296563 769985994 482296563 769985994 769985995'\n",
    "evaluate(pairahh,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67baf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
